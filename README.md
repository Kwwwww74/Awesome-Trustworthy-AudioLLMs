# ğŸ§ Awesome Trustworthy Audio-LLMs  

<div align="center">
  <img src="./images/logo.png" alt="Awesome Trustworthy Audio-LLMs" width="40%" style="margin-top: -20px; margin-bottom: -10px;">
</div>

<p align="center">
<a href=""> <img src="https://img.shields.io/github/stars/Kwwwww74/Awesome-Trustworthy-AudioLLMs?style=flat-square&logo=github" alt="GitHub stars"></a>
<a href=""> <img src="https://img.shields.io/github/forks/Kwwwww74/Awesome-Trustworthy-AudioLLMs?style=flat-square&logo=github" alt="GitHub forks"></a>
<a href=""> <img src="https://img.shields.io/github/issues/Kwwwww74/Awesome-Trustworthy-AudioLLMs?style=flat-square&logo=github" alt="GitHub issues"></a>
<a href=""> <img src="https://img.shields.io/github/last-commit/Kwwwww74/Awesome-Trustworthy-AudioLLMs?style=flat-square&logo=github" alt="GitHub Last commit"></a>
</p>



*A curated and continuously evolving collection of research papers, benchmarks, datasets, and open resources on Trustworthy Audio Large Language Models, covering the full spectrum of safety, robustness, and reliability in audio large models. The collection also includes representative works on audio large models beyond the safety domain.*

---
## ğŸŒIntroduction  

With the rapid developmenst of **Audio Large Language Models (Audio-LLMs)**, ensuring their **trustworthiness and safety** has become an essential research frontier.  

This repository(TALLM) serves as a **comprehensive and community-driven hub** for tracking progress in the field of **trustworthy audio intelligence**. 

It highlights research on:
- ğŸ›¡ï¸ **Safety**
- âš–ï¸ **Fairness**  
- ğŸ”® **Hallucination** 
- ğŸ” **Privacy** 
- âš™ï¸ **Robustness**
- ğŸ’¡ **Interpretability**
- ğŸ’» **Security**
- ...

Together, these works aim toward a future where Audio-LLMs are **not only capable of understanding voices â€” but also worthy of being trusted**.

---

## ğŸ“Œ Table of Content

- [ğŸ§­ Research Collections](#-research-collections)
- [ğŸ’Good Papers](#-good-papers)
- [ğŸ—ï¸ Recent News](#-recent-news)
- [ğŸ¤ How to Contribute](#-how-to-contribute)
- [ğŸ’¬ LLM Safety Discussion](#-llm-safety-discussion)
- [ğŸŒŸ Rising Stars](#-rising-stars)
- [ğŸ™Acknowledgement](#-acknowledgement)


---

## ğŸ§­ Research Collections 
  
- Paper
   - A. Safety
      - [ğŸ“–A1. General](./papers/safety/general.md)
      - [âœï¸A2. Jailbreak](./papers/safety/jailbreak.md)
      - [ğŸ«A3. Alignment](./papers/safety/alignment.md)
      - [ğŸ“šA4. Deepfake](./papers/safety/deepfake.md)
      - [ğŸ’A5. Prompt Injection](./papers/safety/prompt_injection.md)
      - [ğŸ§‘â€ğŸ«A6. Defense](./papers/safety/defense.md)
      - [ğŸ§‘â€ğŸ“A7. Fairness](./papers/safety/fairness.md)
  - B. Security
      - [ğŸ“–B1. General](./papers/security/general.md)
      - [âœï¸B2. Adversarial Examples](./papers/security/adversarial_examples.md)
      - [ğŸ«B3. Attack](./papers/security/attack.md)
      - [ğŸ“šB4. Poison & Backdoor](./papers/security/poison_and_backdoor.md)
  - C. Privacy
      - [ğŸ“–C1. General](./papers/privacy/general.md)
  - D. Interpretability
      - [ğŸ“–D1. General](./papers/interpretability/general.md)
  - E. Fairness
      - [ğŸ“–E1. General](./papers/fairness/general.md)
  - F Hallucination
      - [ğŸ“–F1. General](./papers/hallucination/general.md)
  - G Robustness
      - [ğŸ“–G1.General](./papers/robustness/general.md)

### In addition to the above-mentioned ones:
If you want to learn more about Audio Large Language Models, you can take a look at the following.
  - ğŸš€ [Survey](collections/survey.md)
  - ğŸš€ [Technical Report for Audio Large Language Models](collections/technical_report.md)
  - ğŸš€ [Toolkit](collections/toolkit.md)
  - ğŸš€ [Benchmark](collections/benchmark.md)
  - ğŸš€ [Capability](collections/capability.md)

---

## ğŸ’ Good Papers
- ğŸ† [Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World](https://arxiv.org/abs/2507.06256)
- ğŸ† [Speech-Audio Compositional Attacks on Multimodal LLMs and Their Mitigation with SALMONN-Guard](https://arxiv.org/abs/2511.10222)
- ğŸ† [AHa-Bench: Benchmarking Audio Hallucinations in Large Audio-Language Models](https://openreview.net/forum?id=vCej5sO61x)
- ğŸ† [Hidden in the Noise: Unveiling Backdoors in Audio LLMs Alignment through Latent Acoustic Pattern Triggers](https://arxiv.org/abs/2508.02175v3)

---
## ğŸ—ï¸ Recent News  
- **[2025.11.12]** ğŸ£TALLM is released!!!
- **[2025.11.25]** â›°ï¸Version1 is open to everyone!!!
- **[2025.11.26]** ğŸ TALLM has posted on xhs!!!
- **[2025.12.01]** ğŸ“ˆGeneral capabilities have been collected!!!

---

## ğŸ¤ How to Contribute  

*We welcome contributions from researchers and practitioners!  If you'd like to submit a piece of writing, please write an email to **kaiwenluo74@gmail.com** or write your paper link in **issues part**. Then we can add the article in.*

---

## ğŸ’¬ LLM Safety Discussion

<div align="center">

[Wechat Group](./resource/wechat2.jpg) 


[Discord Group: TALLM](./resource/discord.md)

</div>

---

## ğŸŒŸ Rising Stars
[![Star History Chart](https://api.star-history.com/svg?repos=Kwwwww74/Awesome-Trustworthy-AudioLLMs&type=Date)](https://star-history.com/#Kwwwww74/Awesome-Trustworthy-AudioLLMs&Date)

---

## ğŸ™ Acknowledgement

- Organizers: [Kevin Luo (ç½—å‡¯æ–‡)](https://scholar.google.com/citations?user=XnZXByMAAAAJ&hl=en), [Zhenhong Zhou(å‘¨æŒ¯å®)](https://ydyjya.github.io), [Liang Lin (æ—äº®)](https://scholar.google.com/citations?user=XQNpChIAAAAJ&hl=en)

<p align="center">
  <img src="./images/school.jpg" alt="Awesome Trustworthy Audio-LLMs" width="80%">
</p>
