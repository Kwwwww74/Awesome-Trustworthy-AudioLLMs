# ğŸ§ Awesome Trustworthy Audio-LLMs  
<p align="center">
  <img src="./images/logo.jpg" alt="Awesome Trustworthy Audio-LLMs" width="80%">
</p>

*A curated and continuously evolving collection of research, benchmarks, datasets, and open resources on **Trustworthy Audio Large Language Models (Audio-LLMs)** â€” spanning the entire spectrum of **ALLM Safety**.*

---

## ğŸŒIntroduction  

With the rapid developmenst of **Audio Large Language Models (Audio-LLMs)**, ensuring their **trustworthiness and safety** has become an essential research frontier.  

This repository(TALLM) serves as a **comprehensive and community-driven hub** for tracking progress in the field of **trustworthy audio intelligence**. 

It highlights research on:
- ğŸ›¡ï¸ **Safety**
- âš–ï¸ **Fairness**  
- ğŸ”® **Hallucination** 
- ğŸ” **Privacy** 
- âš™ï¸ **Robustness**
- ğŸ”– **Authentication**
- ğŸ’¡ **Interpretability**
- ğŸ’» **Security**
- ğŸ” **Watermark**

Together, these works aim toward a future where Audio-LLMs are **not only capable of understanding voices â€” but also worthy of being trusted**.

---

## ğŸ§­ Research Collections  

- A. [Safety](./papers/safety)
  - [Surveys & Overviews](./papers/safety/surveys_and_overviews.md)
  - [Attacks & Risks](./papers/safety/attacks_and_risks.md)
  - [Defense & Safety Alignment](./papers/safety/defense_and_safety-alignment.md)
  - [Benchmarks & Evaluation](./papers/safety/benchmarks_and_evaluation.md)

- B. [Fairness](./papers/fairness)
  - [Surveys & Overviews](./papers/fairness/surveys_and_overviews.md)
  - [Attacks & Risks](./papers/fairness/attacks_and_risks.md)
  - [Defense & Safety Alignment](./papers/fairness/defense_and_safety-alignment.md)
  - [Benchmarks & Evaluation](./papers/fairness/benchmarks_and_evaluation.md)

- C. [Hallucination](./papers/hallucination)
  - [Surveys & Overviews](./papers/hallucination/surveys_and_overviews.md)
  - [Attacks & Risks](./papers/hallucination/attacks_and_risks.md)
  - [Defense & Safety Alignment](./papers/hallucination/defense_and_safety-alignment.md)
  - [Benchmarks & Evaluation](./papers/hallucination/benchmarks_and_evaluation.md)

- D. [Privacy](./papers/privacy)
  - [Surveys & Overviews](./papers/privacy/surveys_and_overviews.md)
  - [Attacks & Risks](./papers/privacy/attacks_and_risks.md)
  - [Defense & Safety Alignment](./papers/privacy/defense_and_safety-alignment.md)
  - [Benchmarks & Evaluation](./papers/privacy/benchmarks_and_evaluation.md)

- E. [Robustness](./papers/robustness)
  - [Surveys & Overviews](./papers/robustness/surveys_and_overviews.md)
  - [Attacks & Risks](./papers/robustness/attacks_and_risks.md)
  - [Defense & Safety Alignment](./papers/robustness/defense_and_safety-alignment.md)
  - [Benchmarks & Evaluation](./papers/robustness/benchmarks_and_evaluation.md)

- F. [Authentication](./papers/authentication)
  - [Surveys & Overviews](./papers/authentication/surveys_and_overviews.md)
  - [Attacks & Risks](./papers/authentication/attacks_and_risks.md)
  - [Defense & Safety Alignment](./papers/authentication/defense_and_safety-alignment.md)
  - [Benchmarks & Evaluation](./papers/authentication/benchmarks_and_evaluation.md)

- G. [Interpretability](./papers/interpretability)
  - [Surveys & Overviews](./papers/interpretability/surveys_and_overviews.md)
  - [Attacks & Risks](./papers/interpretability/attacks_and_risks.md)
  - [Defense & Safety Alignment](./papers/interpretability/defense_and_safety-alignment.md)
  - [Benchmarks & Evaluation](./papers/interpretability/benchmarks_and_evaluation.md)

- H. [Security](./papers/security)
  - [Surveys & Overviews](./papers/security/surveys_and_overviews.md)
  - [Attacks & Risks](./papers/security/attacks_and_risks.md)
  - [Defense & Safety Alignment](./papers/security/defense_and_safety-alignment.md)
  - [Benchmarks & Evaluation](./papers/security/benchmarks_and_evaluation.md)

- I. [Watermark](./papers/watermark)
  - [Surveys & Overviews](./papers/watermark/surveys_and_overviews.md)
  - [Attacks & Risks](./papers/watermark/attacks_and_risks.md)
  - [Defense & Safety Alignment](./papers/watermark/defense_and_safety-alignment.md)
  - [Benchmarks & Evaluation](./papers/watermark/benchmarks_and_evaluation.md)

### More than these
- [Technical Report](./technical_report.md)

---

## ğŸ—ï¸ Recent News  
- **[2025.11.12]** ğŸ£TALLM is released!!! 

---

## ğŸ¤ How to Contribute  

*We welcome contributions from researchers and practitioners!  If you'd like to submit a piece of writing, please write an email to **kaiwenluo74@gmail.com**. Then we can add the article in.*

---

## Acknowledgement

- Organizers: [Kevin Luo (ç½—å‡¯æ–‡)](https://scholar.google.com/citations?user=XnZXByMAAAAJ&hl=en), [Liang Lin (æ—äº®)](https://scholar.google.com/citations?user=XQNpChIAAAAJ&hl=en), [Yibo Zhang (å¼ å¥•åš)], [Zhenhong Zhou(å‘¨æŒ¯å®)](https://ydyjya.github.io)

<p align="center">
  <img src="./images/school.jpg" alt="Awesome Trustworthy Audio-LLMs" width="80%">
</p>
